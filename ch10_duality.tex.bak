%% Placeholder for discussion of duality

%Below are notes for Nov 20
In optimization theory, duality or the duality principle is the principle that optimization problems may be viewed from either of two perspectives, that is, the primal problem or the dual problem.

Let's consider the primal problem formulated as follows,
\begin{align*}
\min \quad&F_0(x) \\
s.t. \quad&F_i(x)\leq 0, i = 1,...,m\\
&h_i(x)= 0, i = 1,...,p
\end{align*}
Note that we do not have any assumptions of convexity here.

So the feasible set for this problem is
$$D = (\cap^m_{i=1}\text{dom}\ F_i)\cap(\cap^p_{i=1}\text{dom}\ h_i)$$ 
and the optimal value is $p^*$, optimal variable is $x^*$.

\begin{definition}[The Lagrangian Function]
	We define the Lagrangian function as follows,
	$$L(x,\lambda,\nu) := F_0(x) + \sum^m_{i=1}\lambda_i F_i(x) + \sum^p_{i=1}\nu h_i(x)$$
	where
	$$\lambda =
	\begin{bmatrix}
		\lambda_1\\
		\lambda_2\\
		\vdots\\
		\lambda_m
	\end{bmatrix},\
	\nu = 
	\begin{bmatrix}
		\nu_1\\
		\nu_2\\
		\vdots\\
		\nu_m
	\end{bmatrix}$$

The pairs $(\lambda, \nu)$ are called the "Lagrange multipliers" or "dual variables", and the domain for the Lagrangian function is given by 
$$\text{dom}\ L = D\times \Re^m \times \Re^p$$
\end{definition}

\begin{definition}[The "dual" function]
	The dual function $g(\cdot, \cdot)$ is defined as 
	\begin{equation*}
	g(\lambda, \nu) = \min_{x\in D}\quad L(x,\lambda,\nu)
	\end{equation*}
	
	Note: removes dependence on $x$.
\end{definition}


\begin{definition}{The dual optimization problem}
	\begin{align*}
	\max_{\lambda, \nu} \quad&g(\lambda, \nu) \\
	s.t. \quad&\lambda \geq 0
	\end{align*}

Note: $\nu_i$ are unconstrained, and we denote the optimal value as $d^*$, optimal dual variables as $\lambda^*$ and $\nu^*$.
\end{definition}



Duality Theory: For most convex optimization problem, $d^* = p^*$.\\


\begin{align*}
\min \quad&F_0(x) \\
s.t. \quad&F_i(x)\leq 0, \quad i = 1,...,m \\
&h_i(x)= 0, \quad i = 1,...,p
\end{align*}

\begin{equation*}
L(x,\lambda,\nu) = F_0(x) + \sum^m_{i=1}\lambda_i F_i(x) + \sum^p_{i=1}\nu_i h_i(x)
\end{equation*}

Dual Function:

\begin{equation*}
g(\lambda, \nu) = \min_{x\in D}\quad L(x,\lambda,\nu) 
\end{equation*}


\begin{align*}
\max \quad&g(\lambda, \nu) \\
s.t. \quad&\lambda \geq 0
\end{align*}

(1) $g(\lambda, \nu)$ is concave in $(\lambda, \nu)$ for all $F_0,...,F_m$, $h_0,...,h_p$.

\begin{equation*}
g(\lambda, \nu) =\min_{x\in D}[F_0(x) + \sum^m_{i=1}\lambda_iF_i(x) + \sum^p_{i=1}\nu_ih_i(x) ]
\end{equation*}


(2) For any:

\begin{enumerate}
	\item Primal feasible $x$ (ie. $F_i(x)\leq 0, \quad i = 1,...,m$, $h_i(x)= 0, \quad i = 1,...,p$
	
	\item Dual feasible $(\lambda, \nu)$ (ie. $\lambda \geq 0$)
	
	\begin{equation*}
	g(\lambda, \nu)\leq F_0(x) \qquad (x, \lambda, \nu) \in \mathcal{C}\times \Re^m_+\times \Re^p
	\end{equation*}
\end{enumerate}

\begin{proof}
	\begin{align*}
	F_0(x) &\geq F_0(x) + \sum^m_{i=1}\lambda_iF_i(x) + \sum^p_{i=1}\nu_ih_i(x)\\
	&\geq \min_{x\in D} [F_0(x) + \sum^m_{i=1}\lambda_iF_i(x) + \sum^p_{i=1}\nu_ih_i(x) ] = g(\lambda, \nu)
	\end{align*}
\end{proof}

The point of greatest interest is $x^*$ where $p^* = F_0(x^*)$.

Plug in: 
\begin{equation*}
p^* = F_0(x^*) \geq g(\lambda, \nu), \quad \forall \text{dual-feasible} (\lambda, \nu)\rightarrow \lambda \geq 0
\end{equation*}

Optimize over $(\lambda, \nu)$ where $(\lambda \geq 0)$ to maintain dual feasibility to get greatest lower bound. 

\begin{equation*}
p^* = F_0(x^*) \geq g(\lambda^*, \nu^*) = d^*
\end{equation*}

$p^* - d^*(\text{optimal duality gap})\geq 0$ $\rightarrow$ "weak-duality".

(4) For convex primal optimization problems, (i.e. $F_i(x)$ convex and $h_i(x)$ affine) and under certain conditions called "constraint qualification"(i.e. not all constraint sets allowed) then $p^* = d^*$ $\rightarrow$ "strong duality"

Slater's conditions: A set of constrains $F_i(x) \leq 0$, $Ax = b$ satisfies Slater's if $\exists x\in D$ s.t. $F_i(x)<0,(\text{feasible set has an interior}) \forall i = 1,...,m$ and $Ax = b$


%Above are notes for Nov 20

% Below are notes for Nov 25
\subsection{Slater Conditions}

A set of constraints $F_i(x)\leq 0$, $i = 1...m$, $Ax = b$, satisfy Slater's conditions if there exists an $x$ s.t.

\begin{enumerate}
	\item $F_i(x) \leq 0\quad i = 1,...,m$
	
	\item $Ax = b$
\end{enumerate}

Can actually weaken a bit, if $F_i$ is affine then $x$ satisfying $F_i(x)\leq 0$ suffices i.e. if $F_i(x) = g_i^Tx + h_i$.

\begin{example}
	Convex problem that doesn't satisfy Slater's:
	\begin{align*}
	\begin{bmatrix}
	(x_1-1) & x_2
	\end{bmatrix}\begin{bmatrix}
	1&0\\
	0&1
	\end{bmatrix}\begin{bmatrix}
	x_1 - 1\\
	x_2
	\end{bmatrix}\leq 1\\
	\begin{bmatrix}
	(x_1+2) & x_2
	\end{bmatrix}\begin{bmatrix}
	1&0\\
	0&0
	\end{bmatrix}\begin{bmatrix}
	x_1 + 2\\
	x_2
	\end{bmatrix}\leq y
	\end{align*}
\end{example}

Feasible set is $(x_1, x_2) = \{(0,0) \}$

\begin{marginfigure}
\centering
\includegraphics[width=1.8in,height=1.8in]{figures/ch10/figure1125_1.png}
%\caption{This is an inserted JPG graphic} 
%\label{fig:graph} 
\end{marginfigure}

\begin{theorem}
	If the primal optimization problem is convex and satisfies Slater's conditions, then $p^* = d^*$
\end{theorem}

Sketch proof for $m = 1$ (i.e. 1 inequality constraint $p = 0$).

Primal problem:

\begin{align*}
\min \quad & F_0(x)\\
s.t. \quad & F_1(x) \leq 0
\end{align*}

$\Rightarrow$optimal solution $p^*$.

Lagrange function: $L(x, \lambda) = F_0(x) + \lambda F_1(x)$

Dual function: $g(\lambda) = \min_{x\in D} L(x,\lambda) = \min_x{F_0(x) + \lambda F_1(x)}$

Dual optimal: 

\begin{align*}
\max \quad & g(\lambda)\\
s.t. \quad & \lambda  \geq 0
\end{align*}

$\Rightarrow$ dual optimal is $d^*$.

To start, define:

\begin{align*}
G &= \{(F_1(x), F_0(x)) \vert x\in D = domF_1\cap domF_0 \}\\
&= \cup_{x\in D}\{(F_1(x), F_0(x)) \}
\end{align*}

\begin{marginfigure}
\centering
\includegraphics[width=1.8in,height=1.8in]{figures/ch10/figure1125_2.png}
%\caption{This is an inserted JPG graphic} 
%\label{fig:graph} 
\end{marginfigure}

We can let:

\begin{align*}
\mathcal{A} &= G + \Re_+ \times \Re_+\\
&= \{(s,t) \vert F_1(x)\leq s, F_0(x)\leq t, x\in D \}\\
&= \cup_{x\in D}\{(s,t)\vert F_1(x)\leq s, F_0(x)\leq t \}
\end{align*}

Observations: 

\begin{itemize}
	\item $F$ contains all information about primal problem.
	
	\item $\mathcal{A}$ contains all points "above" \& to "right" of each point in $G$.
	
	$\rightarrow$ each such point(above and to right) is less interesting than the point in $G$.
	
	(1) Perhaps higher cost
	
	(2) Perhaps more resources
\end{itemize}

The boundary of $\mathcal{A}$ is specified by the function:
\begin{align*}
p(x) = &\min \quad F_0(x)\\
&s.t. \quad F_i(x) \leq u
\end{align*}
($p$ is the boundary, $\mathcal{A}$ lies above the boundary)

\begin{enumerate}
	\item $p^* = p(0)$
	
	\item $p$ is non-increasing in $\mathcal{U}$
	
	\item $p$ is convex in $\mathcal{U}$
	
	\item $\mathcal{A} = epi\, p$
\end{enumerate}
Proof of (1): 
\begin{proof}
	As $u$ gets larger, feasible set of the $p(u)$ optimization gets larger so objective cannot increase $\rightarrow$ therefore non-increasing.
\end{proof}

Proof of (2):

\begin{proof}
	Convexity of
	\begin{align*}
	p(x) = &\min \quad F_0(x)\\
	&s.t. \quad F_i(x) \leq u
	\end{align*}
	
	Need to show $\forall u_1, u_2\in domp$, $\forall \lambda\in [0,1]$:
	
	\begin{equation*}
	p(\lambda u_1 + (1-\lambda)u_2) \leq \lambda  p(u_1) + (1-\lambda)p(u_2)
	\end{equation*}
	
	Let
	
	\begin{align*}
	x_i = &arg \min \quad F_0(x)\\
	&s.t. \quad F_i(x) \leq u_i
	\end{align*}
	
	i.e. $F_0(x_1) = p(u_1)\& F_0(x_2) =p(u_2)$
	
	Let $\tilde{x} = \lambda x_1 + (1-\lambda)x_2$ $\leftarrow$ $x_1\in domF_1\cap domF_0\cap \{x\vert F_1(x)\leq u_1 \}$, $x_2\in domF_1\cap domF_0\cap \{x\vert F_2(x)\leq u_2 \}$($x_1$, $x_2$ from different sets)
	
	\begin{align*}
	F_1(\tilde{x}) &= F_1(\lambda x_1 + (1-\lambda)x_2)\quad (\text{Since } F_1\text{ is convex}, \tilde{x}\in domF_1)\\
	&\leq \lambda F_1(x_1) + (1-\lambda)F_1(x_2)\quad (\text{Since } F_1 \text{ is convex})\\
	&\leq \lambda u_1 + (1-\lambda)u_2 \quad (\text{Since } F_i(x_i) \leq u_i)
	\end{align*}
	
	Hence 
	
	\begin{equation*}
	\tilde{x} \in domF_1 \cup domF_0 \cup \{x\vert F_1(x)\leq \lambda u_1 + (1-\lambda)u_2 \}
	\end{equation*}
	
	
	That is: $\tilde{x}$ is a feasible point for opt problem $p(\lambda u_1+(1-\lambda)u_2)$	
\end{proof}

Think about tradeoff between $F_1(x)$ and $F_0(x)$ in a slightly different way:


\begin{align*}
\min_{(s,t)} \quad&\lambda s + t\\
\text{where} \quad&(s,t) \in \mathcal{A}
\end{align*}

$\Leftrightarrow$

\begin{align*}
\min \quad&\begin{bmatrix}
\lambda &1 
\end{bmatrix}\begin{bmatrix}
s\\
t
\end{bmatrix}\\
\text{where} \quad &(s,t) \in \mathcal{A}
\end{align*}

\begin{marginfigure}
\centering
\includegraphics[width=1.8in,height=1.8in]{figures/ch10/figure1125_3.png}
%\caption{This is an inserted JPG graphic} 
%\label{fig:graph} 
\end{marginfigure}

For a given $\lambda$ optimum is attained by some point $(s^*, t^*)$ on boundary of $\mathcal{A}$. Point on boundary is a function of $\lambda$ $(s^*(\lambda), t^*(\lambda)) = (F_1(x^*(\lambda)), F_0(x^*(\lambda)))$. 

Consider any point $(s,t)\in \mathcal{A}$:

\begin{align*}
\begin{bmatrix}
\lambda &1
\end{bmatrix}\begin{bmatrix}
F_1(x^*(\lambda))\\
F_0(x^*(\lambda))
\end{bmatrix}&\leq \begin{bmatrix}
\lambda &1
\end{bmatrix}\begin{bmatrix}
s\\
t
\end{bmatrix}\quad  (*)\\
0&\leq \begin{bmatrix}
\lambda & 1
\end{bmatrix}(\begin{bmatrix}
s\\
t
\end{bmatrix} - \begin{bmatrix}
F_1(x^*(\lambda))\\
F_0(x^*(\lambda))
\end{bmatrix})
\end{align*}

\begin{enumerate}
	\item This optimization yields a tangent plane "supporting hyperplane"
	
	\item In this $2-D$ picture, supporting hyper-plane is a line, change $"\leq"$ in $(*)$ to get line 
	
	\begin{equation*}
	c =\lambda s + t
	\end{equation*} of $(*)$.
	
	re-arrange $t = c - \lambda s$.
\end{enumerate}


This is the problem we just talked about:

\begin{align*}
\min_{(s,t)\in \mathcal{A}} \quad \lambda s + t &= \lambda s^* + t^*\\
&= \lambda F_1(x^*(\lambda)) + F_0(x^*(\lambda))\\
&= \min_{x\in D} \quad[\lambda F_1(x) + F_0(x)]\\
&= g(\lambda) 
\end{align*} the "Dual Function"

Put together pieces:






\begin{itemize}
	\item The dual function $g(x)$ specifies the $y-$intercept of the tangent line of slope $-\lambda$.
	
	\item Last time proves $g(\lambda)$ is a lower bound on $p^*$ as long as $\lambda$ are dual-feasible ($\lambda \geq 0$)
	
	\item The $y-$intercept is a lower bound on $p^*$
\end{itemize}

Get best lower bound by maximizing $g(\lambda)$ over $\lambda > 0$, solve:

\begin{align*}
\max \quad &g(\lambda)\\
s.t. &\lambda \geq 0
\end{align*}




% Above are notes for Nov 25



% Below are notes for Nov 27

\begin{align*}
\max \quad &F_0(x)\\
s.t. \quad&F_1(x) \leq 0\\
\\
L(x,\lambda) &= F_0(x) + \lambda F_1(x)\\
g(\lambda) &= \min_{x\in D} L(x,\lambda)\\
d^* &= \max \quad g(\lambda)\quad s.t.\quad \lambda \geq 0 
\end{align*}

\begin{equation*}
\mathcal{A} =\{(s,t)\vert F_1(x)\leq s, F_0(x)\leq t, x\in D \}
\end{equation*}


\begin{marginfigure}
\centering
\includegraphics[width=1.8in,height=1.8in]{figures/ch10/figure1127_1.png}
%\caption{This is an inserted JPG graphic} 
%\label{fig:graph} 
\end{marginfigure}



\subsection{"Pricing" Interpretation}


\begin{align*}
\min \quad & F_0(x)\\
s.t.\quad & F_i(x) \leq 0,\quad i = 1,...,m\\
& h_i(x) = 0,\quad i = 1,...,p
\end{align*}

$\rightarrow$ reformulate as an unconstrained problem by introducing $I\& \tilde{I}$


\begin{equation}
\label{eq6}
I(x)=\left\{
\begin{aligned}
0 & , & x\leq 0 \\
\infty & , & x>0
\end{aligned}
\right.
\end{equation}

\begin{marginfigure}
\centering
\includegraphics[width=1.8in,height=1.8in]{figures/ch10/figure1127_2.png}
%\caption{This is an inserted JPG graphic} 
%\label{fig:graph} 
\end{marginfigure}

\begin{equation}
\label{eq6}
\tilde{I}(x)=\left\{
\begin{aligned}
0 & , & x= 0 \\
\infty & , & \text{else}
\end{aligned}
\right.
\end{equation}


\begin{marginfigure}
\centering
\includegraphics[width=1.8in,height=1.8in]{figures/ch10/figure1127_3.png}
%\caption{This is an inserted JPG graphic} 
%\label{fig:graph} 
\end{marginfigure}


\begin{equation*}
\min_x\quad F_0(x) + \sum^m_{i=1}I(F_i(x)) + \sum^p_{i=1}\tilde{I}(h_i(x)) \qquad (*)
\end{equation*}

$\Rightarrow$ Same problem but with "hard" penalties

$I$ and $\tilde{I}$

\begin{equation*}
F_0(x) + \sum^m_{i=1}\lambda_i F_i(x) + \sum^p_{i=1}\nu_i h_i(x)
\end{equation*}

$\lambda_i$ = "price" for violating constraint $F_i$, $\mu_i$ = "price" for violating constraint $h_i$.

If strong duality holds:

\begin{align*}
(*) &= \max_{\lambda, \nu, \lambda \geq 0}\quad [\min_x\quad F_0(x) + \sum^m_{i=1}\lambda_iF_i(x) + \sum^p_{i=1}\nu_ih_i(x)]\\
&= \max_{\lambda, \nu}\quad g(\lambda, \nu)\qquad \lambda \geq 0
\end{align*}

Adjust prices $\lambda, \nu$ so that the solution to relaxed problem matrices the solution to primal
\subsection{Sensitivity Analysis}

\begin{marginfigure}
\centering
\includegraphics[width=1.8in,height=1.8in]{figures/ch10/figure1127_4.png}
%\caption{This is an inserted JPG graphic} 
%\label{fig:graph} 
\end{marginfigure}

$\rightarrow$ At dual optimum slope of tangent is $-\lambda^*$

$\rightarrow$
 If change constraint by $\epsilon$, optimum value will change by something like $(-\epsilon \lambda^*)$.
 
 
\begin{align*}
p^*(u,v) = \min \quad &F_0(x) \\
s.t.\quad & F_i(x) \leq 0,\quad i = 1,...,m\\
& h_i(x) = 0,\quad i = 1,...,p
\end{align*}




$\rightarrow$ $u_i<0$ "tighten" constraint, $u_i>0$ loosen constraint, $v_i\neq 0$ change set-point.

$\rightarrow$ Same as $p(u)$ in last lecture.

$\rightarrow$ Note $p^*(0,0) = p^*$ optimal value unconstrained problem

$\rightarrow$ relate $p^*(u,v)$ to $p^*(0,0)$\\

\begin{itemize}
	\item Let $(\lambda^*, \nu^*)$ be optimal dual variables for unperturbed problem
	
	\item Consider a convex optimization problem satisfying Slater's $\rightarrow$ strong duality holds
	
	\begin{align*}
	p^*(0,0) &= g(\lambda^*, \nu^*)\\
	&= \min_{x\in D} L(x, \lambda^*, \nu^*)\\
	&\leq F_0(x) + \sum^m_{i=1}\lambda_i^* F_i(x) + \sum^p_{i=1}\nu_i^* h_i(x)\\
	&\leq F_0(x) + \sum^m_{i=1}\lambda_i^* u_i + \sum^p_{i=1}\nu^*_iv_i\\
	&= F_0(x) + (\lambda^*)^Tu+(\nu^*)^Tv
	\end{align*}
\end{itemize}
Focus in on $x\in D$ s.t. $x$ is optimal for perturbed problem

i.e. $F_0(x)=p^*(u,v)$

$\Rightarrow$ $p^*(u,v) \geq p^*(0,0) - (\lambda^*)^Tu - (\nu^*)^Tv$

\begin{enumerate}
	\item E.g. If $\lambda_i >> 0$ and tighten constraint $F_i$ slightly so that $F_i(x)\leq -\epsilon < 0$\\
	
	\begin{equation*}
	p^*(u,v)\geq p^*(0,0) - (\lambda^*)^Tu - (\nu^*)^Tv
	\end{equation*}
	
	\item Note not symmetric in general, big relaxation in constraint doesn't necessary mean big drop in cost.
	
	\item If $p(u,v)$ is differentiable, then have symmetry for small perturbations. 
\end{enumerate}

\subsection{Lagrange Method}
To solve:

\begin{align*}
\min_x\quad F_0(x)\\
s.t. \quad F_i(x) \leq 0,\quad i = 1,...,m
\end{align*}

\begin{enumerate}
	\item First write Lagrangian: $L(x, \lambda) = F_0(x) + \sum^m_{i=1}\lambda_iF_i(x)$
	
	\item Solve for dual $g(\lambda) = \min_{x} L(x, \lambda)$
	
	\item Find $\lambda^* = arg\, \min g(\lambda)$, $s.t. \quad \lambda \geq 0$
	
	\item Recover primal optimal $x^*$ by solving:
	
	\begin{equation*}
	arg\, \min[L(x, \lambda^*) = F_0(x) + \sum^m_{i=1}\lambda_i^*F_i(x)]
	\end{equation*}
\end{enumerate}

\begin{itemize}
	\item Nice approach if problem has nice structure, in particular if easy to solve for $(\lambda^*, \nu^*)$ analytically or numertically. 
	
	\item Even if $(\lambda^*, \nu^*)$ are unique, the $x$ that minimized $L(x, \lambda^*, \nu^*)$ may not be.
\end{itemize}



\begin{example}
	Largrange Duality for LS problems
	\begin{align*}
	\min_x \quad &\Vert x \Vert_2^2\\
	s.t.\quad &Ax = b
	\end{align*}
	
	"under-determined LS", $x^* = A^T(AA^T)^{-1}b$, $rank(A) = m$
	
	(1) Form Lagrangian $L(x, \nu) = x^Tx + \nu^T(Ax - b)$
	
	
	(2) Evaluate dual
	
	\begin{align*}
	g(\lambda) &= \min_x \quad L(x, \nu)\\
	\frac{\partial}{\partial x} L(x, \nu) &= 2x+A^T\nu = 0\Rightarrow x^*(\nu) = -\frac{1}{2}A^T\nu
	\end{align*}
	
	
	(3) Find
	
	
	\begin{align*}
	\max_{\nu} g(\nu) &= \max_{\nu} L(x^*(\nu)\nu)\\
	&= \max_{\nu}[x^Tx + \nu^T(Ax - b)]\\
	&= \max_{\nu}[\frac{1}{4}\nu^TAA^T\nu + \nu^T(A(-\frac{1}{2}A^T\nu)-b)]\\
	&= \max_{\nu}[\frac{1}{4}\nu^TAA^T\nu - \frac{1}{2}\nu^TAA^T\nu - \nu^Tb]\\
	&= \max_{\nu}[-\frac{1}{4}\nu^TAA^T\nu - \nu^Tb]
	\end{align*}
\end{example}

\begin{align*}
\frac{\partial}{\partial \nu}(-\frac{1}{4}\nu^TAA^T\nu &- \nu^Tb)\\
\frac{1}{4}2AA^T\nu - b &= 0\\
(AA^T)\nu &= -2b\\
\nu^* &= -2(AA^T)^{-1}b
\end{align*}

Substitute into $x^*(\nu)$ to get:

\begin{align*}
x^*(\nu^*) &= -\frac{1}{2}A^T(-2(AA^T)^{-1}b)\\
&= A^T(AA^T)^{-1}b
\end{align*}

Example: Lagrange Duality For LS problems
\begin{align*}
\min_x \quad & \Vert x\Vert^2_2\\
s.t. \quad & Ax = b
\end{align*}

"under-determined LS": $x^* = A^T(AA^T)^{-1}b$.

\begin{equation*}
\frac{1}{4}\nu^TAA^T\nu+\nu^Tb
\end{equation*}

$\Rightarrow$ same as the following $\min_y\quad \Vert\frac{1}{2}A^T\nu + x_0\Vert^2_2$ for any $x_0$ s.t. $Ax_0 = b$.

\begin{align*}
\Vert \frac{1}{2}A^T\nu + x_0\Vert_2^2 &= (\frac{1}{2}A^T\nu+x_0)^T(\frac{1}{2}A^T\nu+x_0)\\
&= \frac{1}{4}\nu^TAA^T\nu + 2\frac{1}{4}\nu^TAx_0 + x_0^Tx_0\\
&= \frac{1}{4}\nu^TAA^T\nu + \nu^Tb+x_0^Tx_0
\end{align*}

Final interpretation:

\begin{align*}
\min \quad & F_0(x)\\
s.t. \quad & F_i(x)\leq 0\quad i = 1,...,m
\end{align*}
Connect to problems with multiple (vector)

Objective $(F_0,F_1,...,F_m)$

One approach is to "scalarize" its objective

\begin{equation*}
F_0(x) + \lambda F_1(x) + \cdots + \lambda_mF_m(x) = F_0(x) + \sum^m_{i=1}\lambda_iF_i(x)
\end{equation*}

% Above are notes for Nov 27

