%% Placeholder for discussion of duality

%Below are notes for Nov 20
In optimization theory, duality or the duality principle is the principle that optimization problems may be viewed from either of two perspectives, that is, the primal problem or the dual problem.

Let's consider the primal problem formulated as follows,
\begin{align*}
	\min \quad&F_0(x) \\
	s.t. \quad&F_i(x)\leq 0, i = 1,...,m\\
	&h_i(x)= 0, i = 1,...,p
\end{align*}
Note that we do not have any assumptions of convexity here.

So the feasible set for this problem is
$$D = (\cap^m_{i=1}\text{dom}\ F_i)\cap(\cap^p_{i=1}\text{dom}\ h_i)$$ 
and the optimal value is $p^*$, optimal variable is $x^*$.

\begin{definition}[The Lagrangian Function]
	We define the Lagrangian function as follows,
	$$L(x,\lambda,\nu) := F_0(x) + \sum^m_{i=1}\lambda_i F_i(x) + \sum^p_{i=1}\nu_i h_i(x)$$
	where
	$$\lambda =
	\begin{bmatrix}
	\lambda_1\\
	\lambda_2\\
	\vdots\\
	\lambda_m
	\end{bmatrix},\
	\nu = 
	\begin{bmatrix}
	\nu_1\\
	\nu_2\\
	\vdots\\
	\nu_p
	\end{bmatrix}$$
	
	The pairs $(\lambda, \nu)$ are called the "Lagrange multipliers" or "dual variables", and the domain for the Lagrangian function is given by 
	$$\text{dom}\ L = D\times \reals^m \times \reals^p$$
\end{definition}

\begin{definition}[The "dual" function]
	The dual function $g(\cdot, \cdot)$ is defined as 
	\begin{equation*}
		g(\lambda, \nu) = \min_{x\in D}\quad L(x,\lambda,\nu)
	\end{equation*}
	
	Note: removes dependence on $x$.
\end{definition}


\begin{definition} The dual optimization problem is formulated as
	\begin{align*}
		\max_{\lambda, \nu} \quad&g(\lambda, \nu) \\
		s.t. \quad&\lambda \geq 0
	\end{align*}
	
	Note: $\nu_i$ are unconstrained, and we denote the optimal value for dual problem as $d^*$, optimal dual variables as $\lambda^*$ and $\nu^*$.
\end{definition}


\subsection{Duality theory}
The duality theory says that, \textbf{for most convex optimization problem}, we have $d^* = p^*$, that is, the primal optimum equals to the dual optimum.

Recall the problem formulations previously, the primal optimization problem is formulated as 
\begin{align*}
	\min \quad&F_0(x) \\
	s.t. \quad&F_i(x)\leq 0, \quad i = 1,\cdots,m \\
	&h_i(x)= 0, \quad i = 1,\cdots,p
\end{align*}

The Lagrange function is given by 
\begin{equation*}
	L(x,\lambda,\nu) = F_0(x) + \sum^m_{i=1}\lambda_i F_i(x) + \sum^p_{i=1}\nu_i h_i(x)
\end{equation*}

The dual function is given by
\begin{equation*}
	g(\lambda, \nu) = \min_{x\in D}\quad L(x,\lambda,\nu) 
\end{equation*}

So the dual optimization problem is formulated as 
\begin{align*}
	\max \quad&g(\lambda, \nu) \\
	s.t. \quad&\lambda \geq 0
\end{align*}



\vspace{0.3cm}
\noindent\textbf{A few observations}
\begin{enumerate}
	
	\item $g(\lambda, \nu)$ is concave in $(\lambda, \nu)$ for all $F_0,...,F_m$, $h_0,...,h_p$.
	
	\begin{proof}
		Recall that
		$$g(\lambda, \nu) =\min_{x\in D}[F_0(x) + \sum^m_{i=1}\lambda_iF_i(x) + \sum^p_{i=1}\nu_ih_i(x) ]$$
		
		First, notice that Lagrange function is an affine function in $(\lambda, \nu)$ so it is concave(of course it is convex at the same time). Secondly, note that the dual function is a pointwise infimum of a family of affine functions in $(\lambda, \nu)$, and thus $g(\lambda, \nu)$ is concave.
	\end{proof}
	
	\item For any primal feasible $x$ (i.e., $F_i(x)\leq 0, \forall i = [m]$, $h_i(x)= 0,\forall i = [p]$ and dual feasible $(\lambda, \nu)$ (i.e., $\lambda \geq 0$), we have
	$$g(\lambda, \nu)\leq F_0(x)$$
	for any tuple $(x, \lambda, \nu) \in \mathcal{C}\times \reals^m_+\times \reals^p$, where $\mathcal{C}$ is the feasible set of the primal problem (contains all feasible $x$).
	
	\begin{proof}
		Notice that, we have
		\begin{align*}
			F_0(x) &\geq F_0(x) + \sum^m_{i=1}\lambda_iF_i(x) + \sum^p_{i=1}\nu_ih_i(x)\\
			&\geq \min_{x\in D} [F_0(x) + \sum^m_{i=1}\lambda_iF_i(x) + \sum^p_{i=1}\nu_ih_i(x)] \\
			&= g(\lambda, \nu)
		\end{align*}
		where the first summation on r.h.s is negative due to $\lambda_i\geq 0$ and $F_i(x)\leq 0$, and the second summation equals to zero due to $h_i(x)=0$. 
		
		Thus the desired result can be obtained by the definition of $\min$ function and dual function.
	\end{proof}
	
	The point of greatest interest is $x^*$, where $p^* = F_0(x^*)$.
	
	Plug in to the above inequality, for all dual feasible $(\lambda, \nu)$ (i.e., for $\lambda \geq 0$), we have
	\begin{equation*}
		p^* = F_0(x^*) \geq g(\lambda, \nu)
	\end{equation*}
	
	Optimize over $(\lambda, \nu)$ where $\lambda \geq 0$ in order to maintain dual feasibility, we can get the greatest lower bound,
	\begin{equation*}
		p^* = F_0(x^*) \geq g(\lambda^*, \nu^*) = d^*
	\end{equation*}
	
	That is, we have the so called \textbf{weak duality}, $p^*\geq d^*$. 
	
	Furthermore, we refer to the difference $p^* - d^*$ as the \textbf{optimal duality gap}.
	
	
	\item For convex primal optimization problems, (i.e., $F_i(x)$ are convex and $h_i(x)$ are affine) and under certain conditions called "constraint qualification" (i.e., not all constraint sets allowed), the \textbf{strong duality} holds, i.e.,
	$$p^* = d^*$$
	and thus the optimal duality gap is zero.
	
	There are many types of constraint qualification, and we will introduce a simple one called Slater's condition in the next section.
	
\end{enumerate}
	

%Above are notes for Nov 20

% Below are notes for Nov 25
\subsection{Slater Conditions}

\begin{definition}[Slater conditions]
	Consider a primal problem with a set of constraints $F_i(x)\leq 0$, $i = [m]$ and $Ax = b$, it is said to be satisfied the Slater's conditions if there exists an $x\in\text{relint}\ D$ such that
	
	\begin{enumerate}
		\item $F_i(x) < 0,\ \forall i = [m]$
		
		\item $Ax = b$
	\end{enumerate}
	
	Furthermore, if some of the inequality constraints are defined by affine functions, this conditions can be weaken a bit. Suppose $F_i$ are affine for $i=1,\cdots, k$, where $k<m$, then the Slater conditions requires that there exists an $x\in\text{relint}\ D$ such that
	\begin{enumerate}
		\item $F_i(x) \leq 0,\ \forall i = 1,\cdots, k$
		\item $F_i(x) < 0,\ \forall i = k+1,\cdots, m$.
		\item $Ax = b$
	\end{enumerate}
	
\end{definition}

\begin{example}
	Convex problem that doesn't satisfy Slater's:
	\begin{align*}
		\begin{bmatrix}
			(x_1-1) & x_2
		\end{bmatrix}\begin{bmatrix}
			1&0\\
			0&1
		\end{bmatrix}\begin{bmatrix}
			x_1 - 1\\
			x_2
		\end{bmatrix}\leq 1\\
		\begin{bmatrix}
			(x_1+2) & x_2
		\end{bmatrix}\begin{bmatrix}
			1&0\\
			0&0
		\end{bmatrix}\begin{bmatrix}
			x_1 + 2\\
			x_2
		\end{bmatrix}\leq y
	\end{align*}
\end{example}

Feasible set is $(x_1, x_2) = \{(0,0) \}$

\begin{marginfigure}
	\centering
	\includegraphics[width=1.8in,height=1.8in]{figures/ch10/figure1125_1.png}
	%\caption{This is an inserted JPG graphic} 
	%\label{fig:graph} 
\end{marginfigure}

\begin{theorem}
	If the primal optimization problem is convex and satisfies Slater's conditions, then $p^* = d^*$, the strong duality holds.
\end{theorem}

\begin{proof}

We propose a sketch proof for the case $m = 1$, i.e., 1 inequality constraint and there is no equality constraint so $p = 0$.

Given the basic setting for this case, the primal problem is given by
\begin{align*}
	\min \quad & F_0(x)\\
	s.t. \quad & F_1(x) \leq 0
\end{align*}
and we let $p^*$ be the optimal value of the primal problem.

The Lagrange function is:
$$L(x, \lambda) = F_0(x) + \lambda F_1(x)$$

The dual function is
$g(\lambda) = \min_{x\in D} L(x,\lambda) = \min_x{F_0(x) + \lambda F_1(x)}$

The dual optimal problem is formulated as
\begin{align*}
	\max \quad & g(\lambda)\\
	s.t. \quad & \lambda  \geq 0
\end{align*}
and we let $d^*$ be the optimal value of the dual problem.

To start, we define a set
\begin{align*}
	G 
	&= \{(F_1(x), F_0(x)) \vert x\in D = \text{dom}\ F_1\cap \text{dom}\ F_0 \}\\
	&= \cup_{x\in D}\{(F_1(x), F_0(x)) \}
\end{align*}

\begin{marginfigure}
	\centering
	\includegraphics[width=1.8in,height=1.8in]{figures/ch10/figure1125_2.png}
	%\caption{This is an inserted JPG graphic} 
	%\label{fig:graph} 
\end{marginfigure}

and also define the set $\mathcal{A}$
\begin{align*}
	\mathcal{A} 
	&= G + \reals_+ \times \reals_+\\
	&= \{(s,t) \vert F_1(x)\leq s, F_0(x)\leq t, x\in D \}\\
	&= \cup_{x\in D}\{(s,t)\vert F_1(x)\leq s, F_0(x)\leq t \}
\end{align*}

A few observations regarding these two sets:
\begin{itemize}
	\item The set $G$ contains all information about primal problem.
	
	\item The set $\mathcal{A}$ contains all points "above" and to "right" of each point in $G$.
	
	\item Each such point(above and to right) is less interesting than the point in $G$ due to  
	
	(1) Perhaps higher cost
	
	(2) Perhaps more resources
\end{itemize}

The boundary of $\mathcal{A}$ is specified by the function:
\begin{align*}
	p(u) = &\min \quad F_0(x)\\
	&s.t. \quad F_1(x) \leq u
\end{align*}
($p$ is the boundary, $\mathcal{A}$ lies above the boundary)

A few observations regarding $p(u)$:

	(1) $p^* = p(0)$.
	
	(2) $p$ is non-increasing in $u$
	
	(3) $p$ is convex in $u$
	
	(4) $\mathcal{A} = \text{epi}\ p$

\begin{proof}[proof of (1)]
	When $u=0$, we just get the original primal problem so certainly $p^* = p(0)$.
\end{proof}

\begin{proof}[proof of (2)]
		As $u$ gets larger, feasible set of the $p(u)$ optimization gets larger so objective cannot increase $\rightarrow$ therefore non-increasing.
\end{proof}

\begin{proof}[proof of (3)]
	We want to prove the convexity of the problem
	\begin{align*}
		p(u) = &\min \quad F_0(x)\\
		&s.t. \quad F_1(x) \leq u
	\end{align*}
	
    and this means that we need to show $\forall u_1, u_2\in \text{dom}\ p$, $\forall \lambda\in [0,1]$, we have
	$$p(\lambda u_1 + (1-\lambda)u_2) \leq \lambda  p(u_1) + (1-\lambda)p(u_2).$$
	
	Consider $i=1, 2$, let
	\begin{align*}
		x_i = &\arg \min \quad F_0(x)\\
		&s.t. \quad F_1(x) \leq u_i
	\end{align*}
	
	That is, $F_0(x_1) = p(u_1)$ and $F_0(x_2) =p(u_2)$.
	
	Let $\tilde{x} = \lambda x_1 + (1-\lambda)x_2$, and note that
	 $$x_1\in \text{dom}\ F_1\cap \text{dom}\ F_0\cap \{x\vert F_1(x)\leq u_1 \}$$ $$x_2\in \text{dom}\ F_1\cap \text{dom}\ F_0\cap \{x\vert F_1(x)\leq u_2 \}$$
	
	So we can write
	\begin{align*}
		F_1(\tilde{x}) 
		&= F_1(\lambda x_1 + (1-\lambda)x_2)\\
		&\leq \lambda F_1(x_1) + (1-\lambda)F_1(x_2) \\
		&\leq \lambda u_1 + (1-\lambda)u_2
	\end{align*}
	where the first equality is due to $\tilde{x}\in \text{dom}\ F_1$, the first inequality is due to convexity of $F_1$, and the second inequality is due to $F_1(x_i) \leq u_i, i=1, 2.$
	
	Hence, 
	\begin{equation*}
		\tilde{x} \in \text{dom}\ F_1 \cap \text{dom}\ F_0 \cap \{x\vert F_1(x)\leq \lambda u_1 + (1-\lambda)u_2 \}
	\end{equation*}
	
	Therefore, $\tilde{x}$ is a feasible point for the optimization problem $p(\lambda u_1+(1-\lambda)u_2)$	
\end{proof}



Think about the trade-off between $F_1(x)$ and $F_0(x)$ in a slightly different way:
\begin{align*}
	\min_{(s,t)} \quad&\lambda s + t\\
	\text{where} \quad&(s,t) \in \mathcal{A}
\end{align*}
which is equivalent to
\begin{align*}
	\min_{(s,t)} \quad&\begin{bmatrix}
		\lambda &1 
	\end{bmatrix}\begin{bmatrix}
		s\\
		t
	\end{bmatrix}\\
	\text{where} \quad &(s,t) \in \mathcal{A}
\end{align*}

\begin{marginfigure}
	\centering
	\includegraphics[width=1.8in,height=1.8in]{figures/ch10/figure1125_3.png}
	%\caption{This is an inserted JPG graphic} 
	%\label{fig:graph} 
\end{marginfigure}

For a given $\lambda$, the optimum is attained by some point $(s^*, t^*)$ on boundary of $\mathcal{A}$. Point on boundary is a function of $\lambda$, so we can write $$(s^*(\lambda), t^*(\lambda)) = (F_1(x^*(\lambda)), F_0(x^*(\lambda)))$$ 

Consider any point $(s,t)\in \mathcal{A}$:
\begin{align*}
	&
	\begin{bmatrix}
		\lambda &1
	\end{bmatrix}
	\begin{bmatrix}
		F_1(x^*(\lambda))\\
		F_0(x^*(\lambda))
	\end{bmatrix}
	\leq 
	\begin{bmatrix}
		\lambda &1
	\end{bmatrix}
	\begin{bmatrix}
		s\\
		t
	\end{bmatrix}\qquad  (*)\\
	\Leftrightarrow & 0\leq 
	\begin{bmatrix}
		\lambda & 1
	\end{bmatrix}
	\left(
	\begin{bmatrix}
		s\\
		t
	\end{bmatrix} 
	- 
	\begin{bmatrix}
		F_1(x^*(\lambda))\\
		F_0(x^*(\lambda))
	\end{bmatrix}\right)
\end{align*}

\begin{enumerate}
	\item This optimization yields a tangent plane, "supporting hyperplane"
	
	\item In this $2-D$ picture, supporting hyper-plane is a line, change $"\leq"$ in $(*)$ to $"="$ get a line 
	$$c =\lambda s + t$$
	where $c$ is the l.h.s of $(*)$.
	
	Rearrange yields $t = c - \lambda s$.
\end{enumerate}


This is the problem we just talked about:
\begin{align*}
	\min_{(s,t)\in \mathcal{A}} \quad \lambda s + t &= \lambda s^* + t^*\\
	&= \lambda F_1(x^*(\lambda)) + F_0(x^*(\lambda))\\
	&= \min_{x\in D} \quad[\lambda F_1(x) + F_0(x)]\\
	&= g(\lambda) 
\end{align*}
so it is the dual function.

Put these pieces all together:

	(1) The dual function $g(\lambda)$ specifies the $y-$intercept of the tangent line of slope $-\lambda$.
	
	(2) Last time proved $g(\lambda)$ is a lower bound on $p^*$ as long as $\lambda$ are dual-feasible (i.e., $\lambda \geq 0$).
	
	(3) The $y-$intercept is a lower bound on $p^*$, i.e., $c\leq p^{*}$.


Get best lower bound by maximizing $g(\lambda)$ over $\lambda \geq 0$, that is, solve the following optimization problem
\begin{align*}
	\max \quad &g(\lambda)\\
	s.t.\quad &\lambda \geq 0
\end{align*}
which exactly takes the form of dual problem.

\end{proof}


% Above are notes for Nov 25



% Below are notes for Nov 27

%\begin{align*}
%\max \quad &F_0(x)\\
%s.t. \quad&F_1(x) \leq 0\\
%\\
%L(x,\lambda) &= F_0(x) + \lambda F_1(x)\\
%g(\lambda) &= \min_{x\in D} L(x,\lambda)\\
%d^* &= \max \quad g(\lambda)\quad s.t.\quad \lambda \geq 0 
%\end{align*}
%
%\begin{equation*}
%\mathcal{A} =\{(s,t)\vert F_1(x)\leq s, F_0(x)\leq t, x\in D \}
%\end{equation*}
%
%
%\begin{marginfigure}
%\centering
%\includegraphics[width=1.8in,height=1.8in]{figures/ch10/figure1127_1.png}
%%\caption{This is an inserted JPG graphic} 
%%\label{fig:graph} 
%\end{marginfigure}


\vspace{0.3cm}
\subsection{"Pricing" Interpretation}
There is an interesting and intuitive interpretation for the duality theory called the pricing interpretation. Suppose the variable $x$ denotes how an company operates(i.e., "policy") and $F_0(x)$ denotes the cost of operating at policy $x$. Each constraint denotes representing some limit, such as a limit on resources, labor, etc. 

To optimal policy(i.e., $x^*$) with these constraints can be found by solving the problem(consider this is the primal problem)
\begin{align*}
	\min \quad & F_0(x)\\
	s.t.\quad & F_i(x) \leq 0,\quad i = 1,\cdots,m\\
	& h_i(x) = 0,\quad i = 1,\cdots,p
\end{align*}

In the next step, we reformulate this problem as an unconstrained problem by introducing $I$ and $\tilde{I}$, which are given by
\begin{equation}
I(x)=\left\{
\begin{aligned}
0 & , & x\leq 0 \\
\infty & , & x>0
\end{aligned}
\right.
\end{equation}

\begin{marginfigure}
	\centering
	\includegraphics[width=1.8in,height=1.8in]{figures/ch10/figure1127_2.png}
	%\caption{This is an inserted JPG graphic} 
	%\label{fig:graph} 
\end{marginfigure}

\begin{equation}
\tilde{I}(x)=\left\{
\begin{aligned}
0 & , & x= 0 \\
\infty & , & \text{else}
\end{aligned}
\right.
\end{equation}


\begin{marginfigure}
	\centering
	\includegraphics[width=1.8in,height=1.8in]{figures/ch10/figure1127_3.png}
	%\caption{This is an inserted JPG graphic} 
	%\label{fig:graph} 
\end{marginfigure}

So the primal problem can be reformulated as 
$$\min_x\quad F_0(x) + \sum^m_{i=1}I(F_i(x)) + \sum^p_{i=1}\tilde{I}(h_i(x)) \qquad (*)$$

This unconstrained problem is the same as primal one, but with "hard" penalties introducing by $I$ and $\tilde{I}$.

Now, let's consider the case that are more realistic. Suppose the company is allowed to break the limit on their resources by paying an additional cost which is linear in the amount of violation, measure by $F_i$ and $h_i$. More precisely, the additional payment made by the company for the $i$-th constraint is $\lambda_i F_i(x)$, and payments are also made to the company for the constraints that are not right(i.e., $F_i(x)<0$), the $\lambda_i F_i(x)$ represents a payment received by the company. 

So $\lambda_i$ is interpreted as the "price" for violating constraint $F_i$, and similarly we have $\mu_i$ as the "price" for violating constraint $h_i$.

Under this relaxed setting (i.e., not all constraints are satisfied), the problem can be formulated as 
$$F_0(x) + \sum^m_{i=1}\lambda_i F_i(x) + \sum^p_{i=1}\nu_i h_i(x)$$

It's obviously that such formulation takes the from of Lagrange function. If we minimize this function to obtain the minimal total cost and then maximize over $\lambda$ and $\nu$, that is
$$\max_{\lambda, \nu} \min_x F_0(x) + \sum^m_{i=1}\lambda_i F_i(x) + \sum^p_{i=1}\nu_i h_i(x)$$
where we obtain the optimal cost to the company under the least favorable set of prices. We use $d^*$ to denote this optimal value, and it readily follows that we have an interpretation for the weak duality, i.e.,
$$d^* \leq p^*$$


Furthermore, if strong duality holds, the problem $(*)$ (i.e., problem that is equivalent to the primal problem) becomes
\begin{align*}
	(*) 
	&= \max_{\lambda, \nu, \lambda \geq 0}\quad [\min_x\quad F_0(x) + \sum^m_{i=1}\lambda_iF_i(x) + \sum^p_{i=1}\nu_ih_i(x)]\\
	&= \max_{\lambda, \nu} g(\lambda, \nu) \quad \text{where}\ \lambda \geq 0
\end{align*}

Implication: Adjust the prices $\lambda, \nu$ so that the solution to relaxed problem matches the solution to the primal problem.
\subsection{Sensitivity Analysis}
\begin{marginfigure}
	\centering
	\includegraphics[width=1.8in,height=1.8in]{figures/ch10/figure1127_4.png}
	%\caption{This is an inserted JPG graphic} 
	%\label{fig:graph} 
\end{marginfigure}

\quad $\rightarrow$ At dual optimum slope of tangent is $-\lambda^*$

$\rightarrow$
If change constraint by $\epsilon$, optimum value will change by something like $(-\epsilon \lambda^*)$.


We consider the following perturbed version of the original optimization problem (unperturbed), says the perpetuated problem, as follows
\begin{align*}
	p^*(u,v) = \min \quad &F_0(x) \\
	s.t.\quad & F_i(x) \leq u_i ,\quad i = 1,\cdots,m\\
	& h_i(x) = v_i,\quad i = 1,\cdots, p
\end{align*}
where when $u=v=0$ is exactly the same as the unperturbed one.

$\rightarrow$ $u_i<0$ "tighten" constraint, $u_i>0$ loosen constraint, $v_i\neq 0$ change set-point.

$\rightarrow$ Same as $p(u)$ in last lecture.

$\rightarrow$ Note $p^*(0,0) = p^*$ is the optimal value of unperturbed problem.

$\rightarrow$ relate $p^*(u,v)$ to $p^*(0,0)$\\

\begin{itemize}
	\item Let $(\lambda^*, \nu^*)$ be optimal dual variables for unperturbed problem
	
	\item Consider a convex optimization problem satisfying Slater's conditions, i.e., strong duality holds,
	\begin{align*}
		p^*(0,0) &= g(\lambda^*, \nu^*)\\
		&= \min_{x\in D} L(x, \lambda^*, \nu^*)\\
		&\leq F_0(x) + \sum^m_{i=1}\lambda_i^* F_i(x) + \sum^p_{i=1}\nu_i^* h_i(x)\\
		&\leq F_0(x) + \sum^m_{i=1}\lambda_i^* u_i + \sum^p_{i=1}\nu^*_iv_i\\
		&= F_0(x) + (\lambda^*)^Tu+(\nu^*)^Tv
	\end{align*}
\end{itemize}
Our focus in on $x\in D$ s.t. $x$ is optimal for perturbed problem

i.e. $F_0(x)=p^*(u,v)$

$\Rightarrow$ $p^*(u,v) \geq p^*(0,0) - (\lambda^*)^Tu - (\nu^*)^Tv$

\begin{enumerate}
	\item E.g. If $\lambda_i >> 0$ and tighten constraint $F_i$ slightly so that $F_i(x)\leq -\epsilon < 0$
	$$p^*(u,v)\geq p^*(0,0) - (\lambda^*)^Tu - (\nu^*)^Tv$$
	
	\item Note not symmetric in general, big relaxation in constraint doesn't necessary mean big drop in cost.
	
	\item If $p(u,v)$ is differentiable, then have symmetry for small perturbations. 
\end{enumerate}

\subsection{Lagrange Method}
In order to solve the following primal problem,
\begin{align*}
	\min_x &\quad F_0(x)\\
	s.t. &\quad F_i(x) \leq 0,\quad i = 1,\cdots,m
\end{align*}
we propose the Lagrange method as follows:

	Step 1. First write Lagrangian: $L(x, \lambda) = F_0(x) + \sum^m_{i=1}\lambda_iF_i(x)$.
	
	Step 2. Solve for dual function $g(\lambda) = \min_{x\in D} L(x, \lambda)$, where $D$ is the primal feasible set.
	
	Step 3. Find $\lambda^* = \arg\max g(\lambda)$, s.t. $\lambda \geq 0$.
	
	Step 4. Recover the primal optimal $x^*$ by solving $\arg\min L(x, \lambda^*)$, that is, solve
		$$\arg\min F_0(x) + \sum^m_{i=1}\lambda_i^*F_i(x).$$

\noindent\textbf{Remarks:}
\begin{itemize}
	\item It is a nice approach if the problem has a nice structure, in particular if it is easy to solve for $(\lambda^*, \nu^*)$ analytically or numerically. 
	
	\item Even if the dual optimum $(\lambda^*, \nu^*)$ is unique, the primal optimum $x^*$ that minimized $L(x, \lambda^*, \nu^*)$ may not be unique.
\end{itemize}



\begin{example}[Lagrange Duality for LS problems]
	Consider the problem
	\begin{align*}
		\min_x \quad &\Vert x \Vert_2^2\\
		s.t.\quad &Ax = b
	\end{align*}
	where $x\in\reals^n$, $A\in\reals^{p\times n}$, $\rank(A) = p< n$.
	
	Recall the chapter least square, this an under determined LS problem, and the optimal solution is given by 
	$$x^* = A^T(AA^T)^{-1}b$$
	
	To verify that this solution is coincide with the one obtained by Lagrange's method, we proceed following procedure to solve this question.
	
	(1) Form the Lagrange function:
	 $$L(x, \nu) = x^Tx + \nu^T(Ax - b)$$
	
	(2) Solve for the dual function $g(\lambda) = \min_x L(x, \nu)$:
		
		Notice that Lagrange function here is a convex quadratic function of $x$(you may verify this), so simply by the first-order condition, we have
		$$\frac{\partial}{\partial x} L(x, \nu) = 2x+A^T\nu = 0\Rightarrow x^*(\nu) = -\frac{1}{2}A^T\nu$$

	(3) Find the dual optimum $\nu^*$:
	
	Now, we have dual problem as
	\begin{align*}
		\max_{\nu} g(\nu) &= \max_{\nu} L(x^*(\nu), \nu)\\
		&= \max_{\nu}[x^*(\nu)^Tx^*(\nu) + \nu^T(Ax^*(\nu) - b)]\\
		&= \max_{\nu}[\frac{1}{4}\nu^TAA^T\nu + \nu^T(A(-\frac{1}{2}A^T\nu)-b)]\\
		&= \max_{\nu}[\frac{1}{4}\nu^TAA^T\nu - \frac{1}{2}\nu^TAA^T\nu - \nu^Tb]\\
		&= \max_{\nu}[-\frac{1}{4}\nu^TAA^T\nu - \nu^Tb]
	\end{align*}
	
	Note that $g(\nu)$ is a concave quadratic function of $\nu$, and therefore utilize the first-order condition we yields
	\begin{align*}
	&\frac{\partial}{\partial \nu}(-\frac{1}{4}\nu^TAA^T\nu - \nu^Tb)= 0\\
	\Leftrightarrow&-\frac{1}{4} 2AA^T\nu - b = 0\\
	\Leftrightarrow& (AA^T)\nu = -2b\\
	\Leftrightarrow& \nu^* = -2(AA^T)^{-1}b
	\end{align*}

	(4) Substitute into $x^*(\nu)$ to get the primal optimum:
	\begin{align*}
	x^*(\nu^*) 
	&=-\frac{1}{2} A^T v^* \\
	&= -\frac{1}{2}A^T(-2(AA^T)^{-1}b)\\
	&= A^T(AA^T)^{-1}b
	\end{align*}

Hence, the optimal solution is coincide with our previous result in LS chapter, that is, for under-determined LS problem we have $x^* = A^T(AA^T)^{-1}b$.

Furthermore, at step (3), we have the problem
$$\max_{\nu} [- \frac{1}{4}\nu^TAA^T\nu - \nu^Tb ]$$

which is equivalent to 
$$\min_{\nu} [\frac{1}{4}\nu^TAA^T\nu + \nu^Tb ]$$

and it turns out, this minimization problem is equivalent to the following norm minimization problem,
\begin{align*}
\min_\nu\quad & \Vert\frac{1}{2}A^T\nu + x_0\Vert^2_2\\
s.t.\quad & Ax_0 = b 
\end{align*}
since they enjoy the same optimal solution $x^*$, and the difference of the optimal value is just a scalar.

More precisely, that's because
\begin{align*}
	\Vert \frac{1}{2}A^T\nu + x_0\Vert_2^2 
	&= (\frac{1}{2}A^T\nu+x_0)^T(\frac{1}{2}A^T\nu+x_0)\\
	&= \frac{1}{4}\nu^TAA^T\nu + 2\frac{1}{4}\nu^TAx_0 + x_0^Tx_0\\
	&= \frac{1}{4}\nu^TAA^T\nu + \nu^Tb+x_0^Tx_0
\end{align*}

\end{example}


\subsection{A final interpretation}
Consider the problem
\begin{align*}
	\min \quad & F_0(x)\\
	s.t. \quad & F_i(x)\leq 0\quad i = 1,\cdots,m
\end{align*}

We want connect to the problems with multiple (vector) objective $(F_0,F_1,\cdots,F_m)$, and one approach is to "scalarize" the objective as 
\begin{equation*}
	F_0(x) + \lambda F_1(x) + \cdots + \lambda_mF_m(x) = F_0(x) + \sum^m_{i=1}\lambda_iF_i(x)
\end{equation*}

% Above are notes for Nov 27





% Below are notes for Dec 2
\vspace{0.5cm}
\subsection{Dual of LPs}
Consider an LP problem as the primal problem, which is given by
\begin{align*}
\min\quad &c^Tx\\
s.t.\quad &Ax\leq b
\end{align*}
where the constraint is the matrix form of $a_i^T x\leq b_i$, for $i=1,\cdots, m$.

The Lagrange function is 
\begin{align*}
L(x,\lambda) 
&= c^Tx + \sum^m_{i=1}\lambda_i (a_i^Tx-b_i)\\
&= c^Tx+
\begin{bmatrix}
\lambda_1&\lambda_2&\cdots&\lambda_m
\end{bmatrix}
\begin{bmatrix}
a_i^Tx-b_1\\
\vdots\\
a_m^Tx-b_m
\end{bmatrix} \\
&=c^Tx+\lambda^T(Ax-b)\\
&= -\lambda^Tb+(c^T+\lambda^TA)x
\end{align*}

The dual function is
\begin{align*}
g(\lambda) 
&= \min_x L(x,\lambda) \\
&= \min_x[-\lambda^Tb+(c^T+\lambda^TA)x]\\
&=
\label{eq6}
\left\{
\begin{aligned}
-\lambda^Tb &\quad \text{if} & c^T+\lambda^TA=0 \\
-\infty &\quad \text{if} & c^T+\lambda^TA\neq 0
\end{aligned}
\right.
\end{align*}

The dual optimization problem is formulated as
\begin{align*}
\max\quad &g(\lambda)\\
s.t.\quad &\lambda \geq 0
\end{align*}

As we showed above, the dual problem is feasible iff $c^T+\lambda^TA=0$, so in order to maintain the feasibility we may consider the problem with the form
\begin{align*}
\max\quad &g(\lambda)\\
s.t.\quad &\lambda\geq 0\\
&c^T+\lambda^TA=0
\end{align*}

which is equivalent to
\begin{align*}
\max\quad &-\lambda^Tb\\
s.t.\quad &\lambda\geq 0\\
&c^T+\lambda^TA=0
\end{align*}


\textbf{Observations:}
\begin{itemize}
	\item The dual of an LP problem is still an LP problem.
	
	\item It maybe not clear from the form, but we have strong duality holds, so $p^*=d^*$.
\end{itemize}

\begin{center}
\begin{tabular}{|c|c|c|}
	\hline 
	&Primal & Dual\\
	\hline  
	number of variables & $n$ & $m$\\
	\hline 
	number of constraints&$m$&$n+m$\\
	\hline 
\end{tabular}
\end{center}


\vspace{0.3cm}
To verify above results, we show that, for this LP case, the dual of the dual problem is just the given primal problem (i.e., we retrieve the original primal problem).

The dual optimization problem we obtain above can be expressed as follows
\begin{align*}
\min\quad &b^T\lambda\\
s.t.\quad &-\lambda\leq 0\quad\\
&A^T\lambda = -c\quad 
\end{align*}
which has the same optimal solution.

Let $z_i$ be the inequalities multipliers, and $y_i$ be the equality multipliers.

The Lagrange function is
$$L(\lambda,x,y) = b^T\lambda + z^T(-\lambda)+y^T(A^T\lambda + c)$$

The dual function is
\begin{align*}
g(z,y) 
&= \min_{\lambda}L(\lambda,z,y)\\
&= \min_{\lambda}y^Tc+(b^T-z^T+y^TA^T)\lambda\\
&=
\left\{
\begin{aligned}
y^Tc &\quad \text{if}\ b^T-z^T+y^TA^T=0 \\
-\infty &\quad\text{else}
\end{aligned}
\right.
\end{align*}

The dual problem is
\begin{align*}
\max\quad &g(z,y)\\
s.t.\quad &z \geq 0
\end{align*}

To main the feasibility, we may have the form
\begin{align*}
\min\quad &y^Tc\\
s.t.\quad &b^T-z^T+y^TA^T=0\\
&z\geq 0
\end{align*}

Notice that, the constraints
\begin{align*}
b^T-z^T+y^TA^T&=0\\
z&\geq 0
\end{align*}

is equivalent to
$$b^T+y^TA^T \geq 0$$
by a simple rearrangement and substitution.


Thus, this dual problem can also be written as:
\begin{align*}
\max\quad &y^Tc\\
s.t.\quad &b+Ay \geq 0
\end{align*}

$\Leftrightarrow$
\begin{align*}
\max\quad &(-x)^Tc\\
s.t.\quad &b+A(-x) \geq 0
\end{align*}

$\Rightarrow$
\begin{align*}
\min\quad &c^Tx\\
s.t.\quad &Ax \leq b
\end{align*}

Note that the second form is just utilize the change of variable and let $-x=y$, and the third one has exactly the same optimal solution(but not optimal value), and the optimal value have a opposite sign.

By this argument, we show that, the dual of the dual problem is just the original LP problem, it implies the strong duality holds by the validation of weak duality(i.e., use weak duality for twice), since the two inequality holds only if the equality holds.


\subsection{Karush-Kuhn-Tucker(KKT) conditions}
Consider the optimization problem for which primal and dual optimal values are obtained and $p^*=d^*$ (i.e., strong duality holds).

Let $x^*$ be the primal optimum, and $(\lambda^*,\nu^*)$ be the dual optimum.

Consider the primal problem:
\begin{align*}
\max\quad &F_0(x)\\
s.t.\quad &F_i(x)\leq 0\quad i = 1,\cdots,m\\
&h_i(x)\leq 0\quad i = 1,\cdots,p
\end{align*}

Note: we have no assumption of convexity for this problem.

The Lagrange function and the dual function are given by 
\begin{align*}
L(x,\lambda,\nu) &= F_0(x)+\sum^m_{i=1}\lambda_iF_i(x) + \sum^p_{i=1}\nu_ih_i(x)\\
g(\lambda,\nu)&= \min_xL(x,\lambda,\nu)
\end{align*}

Since strong duality holds at $(x^*,\lambda^*,\nu^*)$,
\begin{align*}
F_0(x^*) 
&= g(\lambda^*,\nu^*) \\
&= \min_{x}[F_0(x)+\sum^m_{i=1}\lambda_i^*F_i(x) + \sum^p_{i=1}\nu_i^*h_i(x)]\\
&\leq F_0(x^*) +\sum^m_{i=1}\lambda_i^* F_i(x^*) + \sum^p_{i=1}\nu_i^* h_i(x^*)\\
&\leq F_0(x^*)
\end{align*}


The first inequality is because the primal optimal $x^*$ must minimize $L(x^*,\lambda^*,\nu^*)$, and the second inequality is due to the negativity of the second term on r.h.s. 

We claim that the second inequity must hold at equality, since $F_0(x^*)=F_0(x^*)$, and an interesting result can be derived from this fact.


\vspace{0.3cm}
\textbf{Complementary slackness:}

The complementary slackness condition
$$\sum^m_{i=1}\lambda_iF_i(x^*)=0,\ \forall i\in [m]$$
holds for any primal optimal $x^*$ and any dual optimal $\lambda^*$, when the strong duality holds.

We can express the complementary slackness condition as

	(1) If $i$-th constraint is "active" (i.e., $F_i(x)=0)$, then $\lambda_i^*=0$ or $\lambda_i^*>0$.
	
	(2) If $i$-th constraint is "inactive" (i.e., $F_i(x)<0)$, then $\lambda_i^*=0$.

Conversely,

	(3) If $\lambda_i^*=0$, then $F_i(x^*)=0$ or $F_i(x^*)<0$.
	
	(4) If $\lambda_i^*>0$, then $F_i(x^*)=0$.

\vspace{0.5cm}
Recall the pricing interpretation,

$\rightarrow$ perturb $F_i(x)\leq 0$ to $F_i(x)\leq \epsilon$

$\rightarrow$ $\lambda_i^* = - \frac{d}{d\epsilon}p^*(0,0)$


If constraint is "inactive", then there is slack in resource $i$ but since $\lambda_i^* = 0$, no gain by having more of that resource.

If constraint is "active", then resource is totally used, so cannot use more even if you want to.


\vspace{0.5cm}
We can say more if the problem is differentiable, assume that
\begin{itemize}
	\item $F_i(x)$ and $h_i(x)$ are all differentiable.
	
	\item Strong convexity holds.
\end{itemize}

Observe that $x^*$ minimizes $L(x,\lambda^*,\nu^*)$, and since Lagrangian function is differentiable, we have the first order condition:
\begin{equation*}
\nabla_x L(x,\lambda^*,\nu^*) {\vert}_{x=x^*} = 0
\end{equation*}

Thus, we have the \textbf{KKT conditions}:
\begin{enumerate}
	\item $\nabla_x L(x^*,\lambda^*,\nu^*) = \nabla F_0(x^*)+\sum^m_{i=1}\lambda^*_i \nabla F_i(x^*)+\sum^p_{i=1}\nu_i^*\nabla h_i(x^*)=0$
	
	\item $F_i(x^*) \leq 0,\forall i=[m]$,\  $h_i(x^*)=0,\forall i=[p]$.
	
	\item $\lambda_i^*\geq 0,\forall i=[m]$.
	
	\item $\lambda_i^*F_i(x_i^*)= 0,\forall i=[m]$.
\end{enumerate}

\begin{theorem}\label{kktnecessary}
	If $(x^*,\lambda^*,\nu^*)$ are primal and dual optimal, for a differentiable problem for which strong duality holds, they must satisfy KKT conditions. Note that this is necessary but not sufficient.
\end{theorem}


\begin{theorem}\label{kktsufficient}
	When the primal problem is convex, the KKT condtions are also sufficient for the points to be primal and dual optimal with zero duality gap, that is, 
	
	If
	
		(1) $F_i$ and $h_i$ are all differentiable, and
		
		(2) $F_i$ are convex functions and $h_i$ are affine functions
	
	Then for any points $(\tilde{x},\tilde{\lambda},\tilde{\nu})$ satisfy the KKT conditions, we may have
		
	 	(1)	$\tilde{x}$ is primal optimal, $(\tilde{\lambda},\tilde{\nu})$ is  dual optimal, and
	 	
	 	(2) Duality gap is zero (i.e., Strong duality holds).
	 	

\end{theorem}

\begin{proof}
	Let $(\tilde{x},\tilde{\lambda},\tilde{\nu})$ be a point that satisfy the KKT conditions. 
	
	Notice that, the Lagrange function
	$$L(x,\tilde{\lambda}, \tilde{\nu}) = F_0(x) + \sum^m_{i=1}\tilde{\lambda_i}F_i(x) + \sum^p_{i=1}\tilde{\nu_i}h_i(x)$$
	is a convex function in $x$. 
	
	Therefore, if we can find a point of zero-gradient, that is the global optimum.
	
	The KKT-(1) tells us that , for the point $(\tilde{x},\tilde{\lambda},\tilde{\nu})$ we have
	$$\nabla_xL(\tilde{x},\tilde{\lambda},\tilde{\nu}) = 0$$

	Hence, $\tilde{x}$ minimizes $L(x,\tilde{\lambda},\tilde{\nu})$. 
	
	So the dual function is given by	
	\begin{align*}
	g(\tilde{\lambda}, \tilde{\nu}) 
	&= \min_xL(x,\tilde{\lambda},\tilde{\nu})\\
	&= L(\tilde{x},\tilde{\lambda},\tilde{\nu})\\
	&= F_0(\tilde{x}) + \sum^m_{i=1}\tilde{\lambda_i}F_i(\tilde{x}) + \sum^p_{i=1}\tilde{\nu_i}h_i(\tilde{x})\\
	&= F_0(\tilde{x})
	\end{align*}
	where the third equality comes from the KKT-(2) and KKT-(4).
	
	Since $g(\tilde{\lambda},\tilde{\nu}) = F_0(\tilde{x})$, $\tilde{x}$ and $(\tilde{\lambda},\tilde{\nu})$ have zero duality gap so the strong duality holds, and therefore $\tilde{x}$ is primal optimal and $(\tilde{\lambda},\tilde{\nu})$ is dual optimal.
\end{proof}
So far, we have proposed two theorems regarding KKT conditions. One is necessary and the other one is sufficient. Certainly it is better if there is a theorem that is both necessary and sufficient.

To combine the above results such that KKT is necessary and sufficient, we need the following

	(1) Optimization problem that is differentiable so that KKT conditions exist;
	
	(2) Convex optimization problem so that we can apply Theorem \ref{kktsufficient} (sufficiently);
	
	(3) Strong duality holds so that we can apply Theorem \ref{kktnecessary} (necessity).

To summarize, we have the theorem,
\begin{theorem}
If a convex optimization problem with differentiable objective and constraints functions satisfy Slater's condition(i.e., strong duality holds), then the KKT conditions provide necessary and sufficient conditions for optimality. 
\end{theorem}

% Above are notes for Dec 2




% Below are notes for Dec 4
\vspace{0.5cm}
\subsection{Walter-pouring Problem}
Given the maximization problem
\begin{align*}
\max_{P_1,\cdots,P_n}\quad &\sum^n_{i=1}log[1+\frac{P_i}{N_i}]\\
s.t. \quad & 0 \leq P_i,\ i\in[m]\\
&\sum^n_{i=1}P_i\leq P_T
\end{align*}

\begin{marginfigure}
	\centering
	\includegraphics[width=1.8in,height=1.8in]{figures/ch10/figure1204_1.png}
	%\caption{This is an inserted JPG graphic} 
	%\label{fig:graph} 
\end{marginfigure}
We convert it to the general form (minimize the objective),
\begin{align*}
\min_{P_1,\cdots,P_n}\quad &-\sum^n_{i=1}log[1+\frac{P_i}{N_i}]\\
s.t. \quad & 0 \leq P_i,\ i\in[m]\\
&\sum^n_{i=1}P_i\leq P_T
\end{align*}

The Lagrange function is formulated as
$$L(P, \lambda, \mu) = -\sum^n_{l=1}log_l[1+\frac{P_l}{N_l}] + \lambda(\sum^n_{l=1}P_l-P_T) - \sum^n_{l=1}\mu_lP_l $$

By the KKT condtions, we have
\begin{align*}
(1)\quad &\frac{\partial}{\partial P_i}L(P, \lambda, \mu) = -\frac{N_i}{N_i+P_i}\frac{1}{N_i} + \lambda - \mu_i = 0 \Leftrightarrow N_i+P_i = \frac{1}{\lambda-\mu_i}\\
(2)\quad &P_i \geq 0,\ \forall i\in[m]\ \text{and}\ \sum^n_{l=1}P_l \leq P_T\\
(3)\quad &\lambda\geq 0,\ \mu\geq 0\\
(4)\quad &\lambda(\sum^n_{l=1}P_l - P_T) = 0\ \text{and}\ \mu_iP_i = 0\Leftrightarrow \text{if}\ P_i > 0, \text{then}\ \mu_i =0\ 
\end{align*}

To solve this question,
\begin{enumerate}
	\item First observe that you will use all power since $F_0$ is monotonically increasing in each $P_i$, so we have
	$$\sum^n_{l=1}P_l = P_T$$
	
	\item Look at KKT-(1):
	
	(a) If $P_i>0$ then $\mu_i = 0$ by KKT-(4), and therefore $N_i+P_i = \frac{1}{\lambda}$.
	
	(b) If $P_i= 0$, by KKT-(3) $\mu_i\ge 0$, and therefore $N_i = \frac{1}{\lambda - \mu_i}\geq \frac{1}{\lambda}$.
	
	(c) By KKT-(2), we require $P_i\geq 0$, so we conclude that 
	$$P_i = \max\{\frac{1}{\lambda}-N_i, 0 \}$$
\end{enumerate}
\begin{marginfigure}
	\centering
	\includegraphics[width=1.8in,height=1.8in]{figures/ch10/figure1204_2.png}
	%\caption{This is an inserted JPG graphic} 
	%\label{fig:graph} 
\end{marginfigure}

\vspace{0.3cm}
Let's give you $P_T+\epsilon$ power, says $|u^*| = n^*$, and we increase the power by $\frac{\epsilon}{n^*}$ to each channel (that is active),

So the change in rate for $i$-th channel can be computed as
\begin{align*}
\log[1+\frac{P_i+\frac{\epsilon}{n^*}}{N_i}] - \log[1+\frac{P_i}{N_i}] &= \log[\frac{N_i+P_i+\frac{\epsilon}{n^*}}{N_i+P_i}]\\
&= \log[1+\frac{\frac{\epsilon}{n^*}}{N_i+P_i}] \\
&= \log[1+\frac{\frac{\epsilon}{n^*}}{\frac{1}{\lambda^*}}]\\
&= \log[1+\frac{\epsilon}{n^*}\lambda^*]\\
&\approx \frac{\epsilon\lambda^*}{n^*} 
\end{align*}

Hence, Total change in rate  = $n^*\frac{\epsilon\lambda^*}{n^*} = \epsilon \lambda^*$, where $\lambda^*$ can be computed by
$$\frac{\partial F_o(x^*)}{\partial P_T} = \lambda^*$$

\subsection{Geometric interpretation of KKT}
Consider the primal problem
\begin{align*}
\min \quad & F_0(x)\\
s.t. \quad & F_i(x)\leq 0\quad i=1,\cdots,m\\
&h_i(x) = 0\quad i=1,\cdots,p
\end{align*}
which is equivalent to 
\begin{align*}
\min \quad & F_0(x)\\
s.t. \quad & F_i(x)= 0,\ \forall i\in\{i | F_i(x^*)=0\}\\
&h_i(x) = 0\quad i=1,\cdots,p
\end{align*}

Stacking up the constraints, we may expressed this problem with a linear constraint (in matrix form),
\begin{align*}
\min \quad & F_0(x)\\
s.t. \quad & Ax = b
\end{align*}

Consider the optimum point $x^*$ and small perturbations about $x^*$, i.e., $x^*+\triangle x$ which perturbations stay feasible (so the point $x^*+\triangle x$ is still within feasible set).

By feasibility, we have $A(x^*+\triangle x) = b$, and
$$Ax^* + A\triangle x = b\Leftrightarrow A\triangle x = 0\Leftrightarrow \triangle x \in N(A)$$

Apply first order condition,
\begin{align*}
&L(x,\nu) = F_0(x) +\nu^T(Ax-b)\\
\Leftrightarrow & \nabla_xL(x,\nu) = \nabla F_0(x) + A^T\nu  = 0\\
\Leftrightarrow & \nabla F_0(x) = -A^T\nu
\end{align*}

Because $\nu$ is unconstrained, $-A^{T}\nu$ can by any vector in $R(A^T)$.



\begin{marginfigure}
	\centering
	\includegraphics[width=1.8in,height=1.8in]{figures/ch10/figure1204_3.png}
	%\caption{This is an inserted JPG graphic} 
	%\label{fig:graph} 
\end{marginfigure}

Put together with the condition for optimality of constrained problem, a point $x^*\in\mathcal{C}$ is optimal iff 
$$\langle\nabla F_0(x^*), (y-x^*)\rangle\geq 0,\quad \forall y\in\mathcal{C}$$

Since,
\begin{align*}
\nabla F_0(x^*)^T \triangle x &\geq 0, \forall \triangle x\in N(A)\\
\Leftrightarrow \nabla F_0(x^*) &\perp N(A)\\
\Leftrightarrow \nabla F_0(x^*) &\in N(A)^{\perp} = R(A^T)
\end{align*}






\begin{marginfigure}
	\centering
	\includegraphics[width=1.8in,height=1.8in]{figures/ch10/figure1204_4.png}
	%\caption{This is an inserted JPG graphic} 
	%\label{fig:graph} 
\end{marginfigure}



\subsection{First-order for general problem}
From the first-order condition,
$$\nabla_x L(x,\lambda,\nu) = \nabla F_0(x) + \sum^m_{i=1}\lambda_i\nabla F_i(x) + \sum^p_{i=1}\nu_i \nabla h_i(x) = 0$$

We have
$$\nabla F_0(x) = \sum^m_{i=1}(-\lambda_i)\nabla F_i(x) - \sum^p_{i=1}\nu_i\nabla h_i(x)$$

Let's think about the case $m=1$ and $p=0$, so we have $\nabla F_0(x)=-\lambda_1\nabla F_1(x)$.

However, this method not always work since we require the KKT condition holds, as we show in the following example.

\begin{example}
	\begin{marginfigure}
		\centering
		\includegraphics[width=1.8in,height=1.8in]{figures/ch10/figure1204_5.png}
		%\caption{This is an inserted JPG graphic} 
		%\label{fig:graph} 
	\end{marginfigure}
Consider the optimization problem,
\begin{align*}
\min \quad & x_1+x_2\\
s.t. \quad & (x_1+1)^2 + x_2^2 \leq 1\\
&(x_1-2)^2 + x_2^2 \leq 4
\end{align*}

Note that, this is a convex optimization problem with differentiable objective, and feasible set $\mathcal{C}=\{(0, 0)\}$, a singleton.


If we compute the gradients for objective and constraints, and evaluate the gradient at the point $\{(0, 0)\}$ (since $x$ is only feasible at $\{(0, 0)\}$ ), we may find that
\begin{align*}
\nabla F_0(x) &=
\begin{bmatrix}
1\\
1
\end{bmatrix}\\
\nabla F_1(x) &=
\begin{bmatrix}
2(x_1+1)\\
2x_2
\end{bmatrix}
|_{x=x^*=
	\begin{bmatrix}
	0\\
	0
	\end{bmatrix}
}=
\begin{bmatrix}
2\\
0
\end{bmatrix}\\
\nabla F_2(x) &=
\begin{bmatrix}
2(x_1-2)\\
2x_2
\end{bmatrix}
|_{x=x^*=
	\begin{bmatrix}
	0\\
	0
	\end{bmatrix}
}=
\begin{bmatrix}
-4\\
0
\end{bmatrix}\\
\end{align*}

Apparently, we can not find $\lambda_1$ and $\lambda_2$ such that 
$$\nabla F_0(x) =-\lambda_1\nabla F_i(x) -\lambda_2 \nabla F_2(x) $$

In other words, the first order condition is not applicable here. The reason for this situation is, the Slater's condition does not hold for this problem.

The feasible set here is $\mathcal{C}=\{(0, 0)\}$, it is a singleton. \textbf{For any finite set $\mathcal{C}\in\reals^{n}$, there is no interior point for such set $\mathcal{C}$, that is, $\text{int}(\mathcal{C}) =\emptyset$, and thus $\text{relint}(\mathcal{C}) =\emptyset$ as well.} Recall that, the Slater's condition requires there exist a relative interior point, so the condition fails here, and thus the strong duality and the KKT condition do not hold.


\end{example}


\subsection{Extend duality theory to generalized inequality}
Recall generalized inequalities are defined with respect to proper cones. A cone is proper if it is

	(1) closed
	
	(2) convex
	
	(3) pointed (if $x\in k$ and $-x\in k$, then $x=0$)
	
	(4) Solid


\vspace{0.3cm}
As we want similar properties still hold when we extend to generalized inequality defined a proper cone, recall our previous derivation of weak duality:
\begin{align*}
g(\lambda) &= \min_x[F_0(x) + \sum^m_{i=1}\lambda_iF_i(x)]\\
&\leq F_0(x^*) + \sum^m_{i=1}\lambda_i F_i(x^*) \\
&\leq F_0(x^*)
\end{align*}

To accommodate generalized inequalities, we need to identify what set dual variables need to be restricted to keep the following holds (so that the weak duality holds),
\begin{equation*}
\langle \lambda, F(x)\rangle\leq 0,\ \forall x \text{ feasible}
\end{equation*}

Now, we are considering the feasibility inequality constraints are defined by a cone $k$, and we say that the dual variable need to be restricted in the dual cone $k^*$.
	
A dual cone $k^*$ is defined as 
$$k^*=\{y| \langle x,y\rangle \geq 0,\ \forall x\in k \}$$
and the dual cone $k^*$ is always closed and convex, whether the cone $k$ is convex or not.

Also note that, a cone $k$ is self dual if $k^*=k$. For instance, The non-negative orthant cone ($\reals_+^m$), second order cone and PSD cone ($S^m_+$) are self dual.

With this definition for dual cone, apparently we could keep 
\begin{equation*}
\langle \lambda, F(x)\rangle\leq 0,\ \forall x \text{ feasible}
\end{equation*}
so that the weak duality holds. 


\begin{example}
Recall the SDP problem,
\begin{align*}
\min\quad &c^Tx\\
s.t.\quad &x_1F_1+x_2F_2+\ldots+x_nF_n+G\leq_k 0
\end{align*}
where $x\in\reals^n$, $F_i\in S^m$, $G\in S^m$, the cone $k=S^m_+$.


Let $z\in S^m$ be the dual variable.

The Lagrangian function given by
\begin{align*}
L(x,z) &= c^Tx + \langle z,x_1F_1+\ldots +x_nF_n+G\rangle \\
&= c^Tx + \sum^n_{i=1}\langle z,x_iF_i\rangle+\langle z,G\rangle\\
&= \sum^n_{i=1}x_i(c_i+\langle z, F_i\rangle)+\langle z,G\rangle
\end{align*}
is affine in $x$.

If you are confused where this inner product comes from, recall the definition of Frobenius inner product, for any $A, B\in\reals^{m\times n}$, we have the inner product,
$$\langle A, B\rangle_F = \trace (A^T B)$$
Furthermore, if $A, B\in S^m$, then
$$\langle A, B\rangle_F = \trace (A^T B)=\trace (A B) $$
and also remind yourself, the trace of a square matrix equals to sum of all its eigenvalues.

The dual function is give by
\begin{equation*}
g(z) = \min_x L(x,z)=\left\{
\begin{aligned}
-\infty &\quad\text{if}\ \exists i\ \text{s.t.}\ c_i+Tr(zF_i)\neq 0 \\
Tr(zG) & \quad\text{else}
\end{aligned}
\right.
\end{equation*}

Hence, to maintain the feasibility, the dual optimization problem can be expressed as
\begin{align*}
\max_z\quad &tr(zG)\\
s.t.\quad &tr(zG)=-c_i\quad \forall i=1,\cdots,n\\
&z\geq 0
\end{align*}
where we utilize the fact that $S_+^m$ is self-dual, that is, $(S_+^m)^*= S_+^m$.

In summarize, to formulate the dual problem, what we need to do are
\begin{enumerate}
	\item Given a cone $k$, find the dual cone $k^*$.
	
	\item Restrict multipliers to be in $k^*$.
\end{enumerate}

\end{example}

%$g(z)=\min_x L(x,z)$
%
%$\min[c^Tx-<z_1-(x_1F_1+...+x_nF_n+G)>]$ where $x\in k^*$. If primal feasible, $(x_1F_1+...+x_nF_n+G)$ is in $k=S^m_+$





% Above are notes for Dec 4
