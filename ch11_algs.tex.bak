%% Placeholder for chapter on algorithms
%Below are notes for Dec 2

\subsection{KKT conditions}
Consider: optimization problem for which primal\&dual optimal values are obtained and $p^*=d^*$(ie. strong duality)

$x^*$ is primal optimal

$(\lambda^*,\nu^*)$ is dual optimal


\begin{align*}
\max\quad &F_0(x)\\
s.t.\quad &F_i(x)\leq 0\quad i = 1,...,m\\
&h_i(x)\leq 0\quad i = 1,...,p
\end{align*}

(Note: no assumption of convexity)


\begin{align*}
L(x,\lambda,\nu) &= F_0(x)+\sum^m_{i=1}\lambda_iF_i(x) + \sum^p_{i=1}\nu_ih_i(x)\\
g(\lambda,\nu)&= \min_xL(x,\lambda,\nu)
\end{align*}

Since strong duality holds of $(x^*,\lambda^*,\nu^*)$

\begin{align*}
F_0(x^*) &= g(\lambda^*,\nu^*) = \min_{x}[F_0(x)+\sum^m_{i=1}\lambda_iF_i(x) + \sum^p_{i=1}\nu_ih_i(x)]\\
&\leq F_0(x^*) +\sum^m_{i=1}\lambda_iF_i(x^*) + \sum^p_{i=1}\nu_ih_i(x^*)\\
&\leq F_0(x^*)
\end{align*}

\begin{enumerate}
	\item The primal optimal $x^*$ must minimize $L(x^*,\lambda^*,\nu^*)$
	
	\item To get "=" in (2) need $\lambda^*F_i(x^*)=0,\quad \forall i = 1,...m$
\end{enumerate}
Complementary slackness:

\begin{enumerate}
	\item If $i^{th}$ constraint is "active" (ie. $F_i(x)=0)$ then $\lambda_i^*=0$ or $\lambda_i^*>0$.
	
	\item If $i^{th}$ constraint is "inactive" (ie. $F_i(x)<0)$ then $\lambda_i^*=0$.
\end{enumerate}

Conversely,

\begin{enumerate}
	\item If $\lambda_i^*=0$ then $F_i(x^*_=0)$ or $F_i(x^*)<0$
	
	\item If $\lambda_i^*>0$ then $F_i(x^*_=0)$ 
\end{enumerate}

Recall pricing perspective

$\rightarrow$ perturb $F_i(x)\leq 0$ to $F_i(x)\leq \epsilon$

$\rightarrow$ $\lambda_i^* = \frac{d}{d\epsilon}p^*(0,0)$


If constraint is "inactive" then there is slack in resource $i$ but since $\lambda_i^* = 0$ no gain by having more of that resource.

If constraint is "active" then resource is totally used so cannot use more even if you want to.\\

We can say more if problem is differentiable:

\begin{itemize}
	\item $F_i(x)\& h_i(x)$ all differentiable
	
	\item Still assume strong convexity
\end{itemize}

Recall: Just observed $x^*$ ,minimizes $L(x,\lambda^*,\nu^*)$

$\rightarrow$ since Lagrangian is differentiable:

\begin{equation*}
\triangledown_x L(x,\lambda^*,\nu^*) {\vert}_{x=x^*} = 0
\end{equation*}
("First-order" condition)\\


KKT conditions:

\begin{enumerate}
	\item $triangledown_x L(x,\lambda^*,\nu^*) = \triangledown F_0(x^*)+\sum^m_{i=1}\lambda^*_i+\triangledown F_i(x^*)+\sum^p_{i=1}\nu_i^*\triangledown h_i(x^*)=0$

	\item $F_i(x^*) \leq 0,\quad i=1,...,m,\quad h_i(x^*)=0\quad i=1,...,p$
	
	\item $\lambda_i^*\geq 0\quad i=1,...,m$
	
	\item $\lambda_i^*F_i(x_i^*)= 0\quad i=1,...,m$
\end{enumerate}

\begin{theorem}{}
	If $(x^*,\lambda^*,\nu^*)$ are primal\&dual optimal, for a differentiable problem for which strong duality holds, they must satisfy KKT.
\end{theorem}
(necessary but not sufficient)

\begin{theorem}
	Start with optimization problem:
	\begin{itemize}
		\item $F_i\&h_i$ all differentiable
		
		\item $F_i$ convex \& $h_i$ affine
	\end{itemize}

	Then if any $(\tilde{x},\tilde{\lambda},\tilde{\nu})$ satisfy KKT:
	
	\begin{itemize}
		\item Storng duality holds
		
		\item $\tilde{x}$ is primal optimal
		
		\item $(\tilde{\lambda},\tilde{\nu})$ is dual optimal
	\end{itemize}
\end{theorem}

\begin{proof}
	Prove by convexity assumption \& dual feasible of $\tilde{\lambda}$(KKT)
	
	\begin{equation*}
	L(x,\tilde{\lambda}, \tilde{\nu}) = F_0(x) + \sum^m_{i=1}\tilde{\lambda_i}F_i(x) + \sum^p_{i=1}\tilde{\nu_i}h_i(x)
	\end{equation*}
	
	is a convex function in $x$, therefore therefore if can find a point of zero-gradient, that is global optimum
	
	But KKT-(1) tells us that $\triangledown_xL(\tilde{x},\tilde{\lambda},\tilde{\nu})$ hence $\tilde{x}$ minimizes $L(x,\tilde{\lambda},\tilde{\nu})$
	
	$g(\tilde{\lambda}, \tilde{\nu}) = \min_xL(x,\tilde{\lambda},\tilde{\nu}) = L(\tilde{x},\tilde{\lambda},\tilde{\nu})$
	
	
	\begin{align*}
	L(\tilde{x},\tilde{\lambda},\tilde{\nu}) &= F_0(\tilde{x}) + \sum^m_{i=1}\tilde{\lambda_i}F_i(x) + \sum^p_{i=1}\tilde{\nu_i}h_i(\tilde{x})\\
	&= F_0(\tilde{x})
	\end{align*}
	
	\begin{itemize}
		\item $\Rightarrow$ In other words since $g(\tilde{\lambda},\tilde{\nu}) = F_0(\tilde{x})$, the duality gap is zero $\Rightarrow$ strong duality holds
		
		\item $\Rightarrow$ also by KKT-(2) $\tilde{x}$ is primal feasible.
		
		\item $\Rightarrow$ $(\tilde{\lambda},\tilde{\nu})$ attains $d^*$.
		
		\item $\Rightarrow$ $(\tilde{x})$ attains $p^*$.
		
		\item $\Rightarrow$ $p^* = d^*$
	\end{itemize}
\end{proof}

\begin{theorem}{A}
	(If strong duality holds) Any tuple $(\tilde{x},\tilde{\lambda},\tilde{\nu})$ of primal/dual optimal variables must satisfy KKT (necessary condition for optimality)
\end{theorem}

\begin{theorem}{B}
	(Assume convex problem) If $(\tilde{x},\tilde{\lambda},\tilde{\nu})$ satisfy KKT, $\Rightarrow$ strong duality holds, primal/dual feasible. (sufficient)
\end{theorem}

Want to combine so KKT necessary \& sufficient.

Need:
\begin{enumerate}
	\item optimization problem that is differentiable so KKT conditions exist
	
	\item Convex so have Theorem B (sufficiently)
	
	\item Strong duality to hold (necessity)
\end{enumerate}

$\Rightarrow$ Convex optimization problems that are differentiable \& satisfy Slater's satisfy (1)-(3)

%Above are notes for Dec 2
